{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment 2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f09fe1c-ed04-49d6-b6d2-1333a896d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LINKS_PATH = os.path.join(os.getcwd(), 'movie', 'links.csv')\n",
    "TAGS_PATH = os.path.join(os.getcwd(), 'movie', 'tags.csv')\n",
    "MOVIES_PATH = os.path.join(os.getcwd(), 'movie', 'movies.csv')\n",
    "RATINGS_PATH = os.path.join(os.getcwd(), 'movie', 'ratings.csv')\n",
    "\n",
    "def load_data(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Loading data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6584fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = load_data(RATINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd83225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part A</h2>\n",
    "\n",
    "<p>1. The first aggregation approach is the average method. The main idea behind this\n",
    "approach is that all members are considered equals. So, the rating of an item for a group\n",
    "of users will be given be averaging the scores of an item across all group members.</p>\n",
    "\n",
    "<p>2. The second aggregation method is the least misery method, where one member can act\n",
    "as a veto for the rest of the group. In this case, the rating of an item for a group of users is\n",
    "computed as the minimum score assigned to that item in all group members\n",
    "recommendations.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First let's get helper functions for predicting movie ratings from the previous assignment and prepare data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions from the previous assignment\n",
    "\n",
    "# min_common_percentage = 0.1\n",
    "min_common_items = 2\n",
    "\n",
    "# Implementation of Pearson correlation\n",
    "def get_similarity_between_two_items(user1, user2):\n",
    "    # Find common items\n",
    "    common_items = user1.notna() & user2.notna()\n",
    "    \n",
    "    common_items_count = common_items.sum()\n",
    "    if common_items_count == 0:\n",
    "        return 0  # No common items, no correlation\n",
    "    \n",
    "    # We implement a treshold to avoid meaningless correlations\n",
    "    # Approach 1: Common items percentage\n",
    "    # total_items_user1 = user1.count()\n",
    "    # total_items_user2 = user2.count()\n",
    "    # common_percentage_user1 = common_items_count / total_items_user1\n",
    "    # common_percentage_user2 = common_items_count / total_items_user2\n",
    "    # if common_percentage_user1 < min_common_percentage or common_percentage_user2 < min_common_percentage:\n",
    "    #     return 0  # Not enough common items for a meaningful correlation\n",
    "\n",
    "    # Approach 2: Common items count\n",
    "    if common_items_count < min_common_items:\n",
    "        return 0  # Not enough common items for a meaningful correlation\n",
    "    \n",
    "    # Get the common items\n",
    "    user1_common = user1[common_items]\n",
    "    user2_common = user2[common_items]\n",
    "    \n",
    "    # Pearson correlation requires at least 2 common items\n",
    "    if len(user1_common) < 2:\n",
    "        return 0 \n",
    "    \n",
    "    # Calculate the Pearson correlation coefficient\n",
    "    correlation = user1_common.corr(user2_common)\n",
    "    \n",
    "    if np.isnan(correlation):\n",
    "        return 0  # Handle NaN values\n",
    "    \n",
    "    return max(correlation, 0)  # Return a non-negative correlation\n",
    "\n",
    "def predict_rating(user_id, movie_id, ratings_by_users):\n",
    "    # If the user has already rated the movie, return the known rating\n",
    "    if not np.isnan(ratings_by_users.loc[user_id, movie_id]):\n",
    "        return ratings_by_users.loc[user_id, movie_id]\n",
    "\n",
    "    # Get the users who rated the movie\n",
    "    users_who_rated = ratings_by_users[ratings_by_users[movie_id].notna()].index\n",
    "\n",
    "    # Calculate the similarities and the weighted ratings\n",
    "    similarities = [get_similarity_between_two_items(ratings_by_users.loc[user_id], ratings_by_users.loc[other_user_id]) for other_user_id in users_who_rated]\n",
    "    weighted_ratings = [similarity * (ratings_by_users.loc[other_user_id, movie_id] - ratings_by_users.loc[other_user_id].mean()) for other_user_id, similarity in zip(users_who_rated, similarities)]\n",
    "\n",
    "    # If no one else rated the movie, return the mean rating of the user\n",
    "    if sum(similarities) == 0:\n",
    "        return ratings_by_users.loc[user_id].mean()\n",
    "\n",
    "    # Return the weighted average rating, ensuring it is within the range of 0 - 5\n",
    "    return max(min((sum(weighted_ratings) / sum(similarities)) + ratings_by_users.loc[user_id].mean(), 5), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5278137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the ratings dataframe to a new dataframe for further processing\n",
    "movie_ratings = ratings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8        \n",
       "userId                                                                    \n",
       "1           4.0     NaN     4.0     NaN     NaN     4.0     NaN     NaN  \\\n",
       "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  9       10      ...  193565  193567  193571  193573  193579  193581   \n",
       "userId                   ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN  \\\n",
       "2           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  193583  193585  193587  193609  \n",
       "userId                                   \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN  \n",
       "4           NaN     NaN     NaN     NaN  \n",
       "5           NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 9724 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a pivot table to get the ratings of each movie by each user\n",
    "ratings_by_users = movie_ratings.pivot_table(index='userId', columns='movieId', values='rating', aggfunc='first')\n",
    "ratings_by_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Implementing average agregation and least misery approaches for a set of users<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function has some extensive parameters to allow for more flexibility\n",
    "# userIds: The ids of the users we want to predict the ratings for\n",
    "# all_users_ratings: The movie ratings by all users\n",
    "# predict_na: If True, the function will predict the ratings of the movies that the users haven't rated (True by default)\n",
    "# strategy: The strategy to use for the prediction. Can be 'average' or 'least_misery'\n",
    "# min_num_of_rated_movies: The minimum number rates a movie should have to be considered\n",
    "\n",
    "def group_rating_prediction(userIds, all_users_ratings, strategy='average', useFullDataset=False):\n",
    "    # Get only the data about the users we are interested in\n",
    "    group_users_ratings = all_users_ratings.loc[userIds]\n",
    "\n",
    "    # Remove the movies that no one has rated\n",
    "    group_users_ratings = group_users_ratings.dropna(axis=1, how='all')\n",
    "\n",
    "    # Dataset to use for prediction\n",
    "    if(useFullDataset):\n",
    "        dataset_for_prediction = all_users_ratings.copy()\n",
    "    else:\n",
    "        dataset_for_prediction = group_users_ratings.copy()\n",
    "\n",
    "    # Predict the individual ratings of the movies that the users haven't rated\n",
    "    for user_id in userIds:\n",
    "        for movie_id in group_users_ratings.columns:\n",
    "            group_users_ratings.loc[user_id, movie_id] = predict_rating(user_id, movie_id, dataset_for_prediction)\n",
    "    \n",
    "    if(strategy == 'average'):\n",
    "        # Get the average rating for every movie\n",
    "        movie_ratings_average = group_users_ratings.mean(axis=0)\n",
    "\n",
    "    if(strategy == 'least_misery'):\n",
    "        # Get the least misery rating for every movie\n",
    "        movie_ratings_average = group_users_ratings.min(axis=0)\n",
    "\n",
    "    # Sort the movies by their average rating\n",
    "    movie_ratings_average = movie_ratings_average.sort_values(ascending=False)\n",
    "\n",
    "    return movie_ratings_average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Produce a group of 3 users, and for this group, show the top-10 recommendations, i.e.,\n",
    "the 10 movies with the highest prediction scores that (i) the average method suggests,\n",
    "and (ii) the least misery method suggest</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the given group of users\n",
    "userIds = [1, 2, 3]\n",
    "average_predictions = group_rating_prediction(userIds, ratings_by_users, strategy='average')\n",
    "least_misery_predictions = group_rating_prediction(userIds, ratings_by_users, strategy='least_misery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "2851     4.649425\n",
       "70946    4.649425\n",
       "5181     4.649425\n",
       "849      4.649425\n",
       "5746     4.649425\n",
       "5919     4.649425\n",
       "6835     4.649425\n",
       "7991     4.649425\n",
       "3703     4.649425\n",
       "4518     4.649425\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 10 movies for the given group of users by average rating\n",
    "average_predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "7991     3.948276\n",
       "3703     3.948276\n",
       "5919     3.948276\n",
       "5764     3.948276\n",
       "5746     3.948276\n",
       "26409    3.948276\n",
       "849      3.948276\n",
       "5181     3.948276\n",
       "2851     3.948276\n",
       "1587     3.948276\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 10 movies for the given group of users by least misery rating\n",
    "least_misery_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The ratings are the same for all of the top 10 suggestions. This is caused by the fact that we used the specified group of users to predict missing movie values. There were a lot of movies rated only by one user and in this case the prediction fucntion returns the mean rating of the user<p>\n",
    "\n",
    "<p>To avoid this kind of situation we can use the whole dataset to predict the missing movie ratings(since we use weighted ratings based on person correlation they should be accurate)</p>\n",
    "\n",
    "<p> Let's do it </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the full dataset for prediction\n",
    "userIds = [1, 2, 3]\n",
    "q = group_rating_prediction(userIds, ratings_by_users, strategy='average', useFullDataset=True)\n",
    "least_misery_predictions = group_rating_prediction(userIds, ratings_by_users, strategy='least_misery', useFullDataset=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "2851     4.649425\n",
       "70946    4.649425\n",
       "5181     4.649425\n",
       "849      4.649425\n",
       "5746     4.649425\n",
       "5919     4.649425\n",
       "6835     4.649425\n",
       "7991     4.649425\n",
       "3703     4.649425\n",
       "4518     4.649425\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "70946    5.000000\n",
       "3703     4.980555\n",
       "1587     4.500000\n",
       "4518     4.026903\n",
       "2288     4.000000\n",
       "2851     3.948276\n",
       "6835     3.948276\n",
       "5181     3.948276\n",
       "5919     3.948276\n",
       "5764     3.948276\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_misery_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we can see now the ratings look better, but it required more computing to produce the results</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part B</h2>\n",
    "\n",
    "Define a way for counting the disagreements between the users in a group, and propose a method that takes disagreements into account when computing suggestions for the group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>Idea:</h3>\n",
    "\n",
    " We propose a user-based way of computing suggestions with considering disagreements. The basic idea is to assign weights to each user in a group based on how closely their preferences align with others. The rationale behind this is that users who frequently disagree with the majority of the group should have less influence on the final recommendations. \n",
    "\n",
    " By assigning higher importance to users whose ratings align with the majority, we aim to filter out the impact of individuals who may provide random or intentionally false ratings, or those whose preferences significantly differs from the majority of the group. So with this, this method is able to ignore outliers, as it will assign near-zero weight for these users.\n",
    "\n",
    "In this way, the ratings from these users may not significantly impact the outcome, which is a potential drawback for them. However, this approach could prove advantageous for the majority of the group, ultimately leading to higher overall satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Details of implementation</h3>\n",
    "\n",
    "One way to capture disagreements is to consider the variance or diversity in user ratings within the group. The idea is to, calculate a disagreement matrix, for a group of users, that represents the differences in ratings between each pair of users. One way to measure this difference is by computing the squared differences between their ratings for common items. When computing recommendations for the group, we use a weighted averaging aggregiation, where the weights are inversely proportional to the disagreement factor for a user, which is the average of the mentioned squared differences with all other users. The rationale is that users who tend to disagree less should have more influence on the group recommendations.\n",
    "\n",
    "\n",
    "Before calculating this disagreement matrix, we make the individual predictions for all users in the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disagreement_matrix(ratings_by_relevant_user_matrix: pd.DataFrame) -> np.ndarray:\n",
    "    # Get the number of users and movies\n",
    "    number_of_users = ratings_by_relevant_user_matrix.shape[0]\n",
    "\n",
    "    # Initialize the disagreement matrix\n",
    "    disagreement_matrix = np.zeros((number_of_users, number_of_users))\n",
    "\n",
    "    # Calculate the disagreement matrix\n",
    "    for user1 in range(number_of_users):\n",
    "        for user2 in range(user1 + 1, number_of_users):\n",
    "            # Get the ratings of the two users\n",
    "            user1_ratings = ratings_by_relevant_user_matrix.iloc[user1]\n",
    "            user2_ratings = ratings_by_relevant_user_matrix.iloc[user2]\n",
    "\n",
    "            # Get the common items (there should be no NaN values because we predict them, but we check just in case)\n",
    "            common_items = user1_ratings.notna() & user2_ratings.notna()\n",
    "\n",
    "            if common_items.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate the squared difference between the ratings\n",
    "            disagreement = ((user1_ratings[common_items] - user2_ratings[common_items]) ** 2).sum() / common_items.sum()\n",
    "\n",
    "            # Add the disagreement to the matrix\n",
    "            disagreement_matrix[user1, user2] = disagreement\n",
    "            disagreement_matrix[user2, user1] = disagreement\n",
    "\n",
    "    return disagreement_matrix\n",
    "\n",
    "def group_rating_prediction_with_disagreement(userIds, ratings_by_users):\n",
    "    # Get only the data about the users we are interested in\n",
    "    ratings_by_relevant_users = ratings_by_users.loc[userIds]\n",
    "\n",
    "    # Remove the movies that no one has rated\n",
    "    ratings_by_relevant_users = ratings_by_relevant_users.dropna(axis=1, how='all')\n",
    "\n",
    "    # Predict the individual ratings of the movies that the users haven't rated\n",
    "    for user_id in userIds:\n",
    "        for movie_id in ratings_by_relevant_users.columns:\n",
    "            ratings_by_relevant_users.loc[user_id, movie_id] = predict_rating(user_id, movie_id, ratings_by_users.copy())\n",
    "    \n",
    "    # Calculate the disagreement matrix\n",
    "    disagreement_matrix = calculate_disagreement_matrix(ratings_by_relevant_users)\n",
    "\n",
    "    # user weights will be inversely proportional to the average of their disagreements\n",
    "    weights = 1 / (1 + disagreement_matrix.mean(axis=1))\n",
    "\n",
    "    # the more disagreed the user was with the others the less weight his rating will have\n",
    "    weighted_average = pd.Series(index=ratings_by_relevant_users.columns)\n",
    "    for movie_id in ratings_by_relevant_users.columns:\n",
    "        weighted_average[movie_id] = (ratings_by_relevant_users[movie_id] * weights).sum() / len(userIds)\n",
    "    \n",
    "    # transform the ratings to the range of 0 - 5\n",
    "    weighted_average = weighted_average * 5 / weighted_average.max()\n",
    "    \n",
    "    return weighted_average.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "70946    5.000000\n",
       "3703     4.992078\n",
       "1587     4.824318\n",
       "2288     4.714071\n",
       "101      4.577329\n",
       "6835     4.571495\n",
       "5746     4.571495\n",
       "5181     4.571495\n",
       "5919     4.571495\n",
       "2502     4.460394\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_rating_prediction_with_disagreement(userIds, ratings_by_users).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
